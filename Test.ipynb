{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, MultiHeadAttention, LayerNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = '2019 06 01'\n",
    "# end_date = '2019 08 01'\n",
    "\n",
    "# data_train = data.loc[start_date:end_date]\n",
    "# data_test = data.loc[predict_date]\n",
    "# hourly_mean = data_train.groupby(data_train.index.hour).mean()\n",
    "# predictions = hourly_mean.reindex(data_train.index.hour).fillna(method='ffill')\n",
    "\n",
    "# eval_metrics(data_test['ROI-DA'],hourly_mean['ROI-DA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/cross_validation.html#time-series-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different parameter with selectkbest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[123], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0125\u001b[39m\n\u001b[0;32m      9\u001b[0m colsample_bytree \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m---> 11\u001b[0m XGBM \u001b[38;5;241m=\u001b[39m \u001b[43mXGBM_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43msubsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcolsample_bytree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# score,XGBM = XGBM_training(X_train,y_train)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[118], line 11\u001b[0m, in \u001b[0;36mXGBM_model\u001b[1;34m(X, y, learning_rate, n_estimators, max_depth, subsample, colsample_bytree)\u001b[0m\n\u001b[0;32m      7\u001b[0m colsample_bytree \u001b[38;5;241m=\u001b[39m colsample_bytree\n\u001b[0;32m      9\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m---> 11\u001b[0m XGBM \u001b[38;5;241m=\u001b[39m \u001b[43mXGBRegressor\u001b[49m(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate, n_estimators\u001b[38;5;241m=\u001b[39mn_estimators, max_depth\u001b[38;5;241m=\u001b[39m max_depth,\n\u001b[0;32m     12\u001b[0m                                         subsample\u001b[38;5;241m=\u001b[39m subsample, colsample_bytree \u001b[38;5;241m=\u001b[39m colsample_bytree, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     14\u001b[0m XGBM\u001b[38;5;241m.\u001b[39mfit(X,y)\n\u001b[0;32m     16\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XGBRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "k_best = 10  # Par exemple, sélectionner les 10 meilleures caractéristiques\n",
    "selector = SelectKBest(score_func=f_regression, k=k_best)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "subsample = 1\n",
    "n_estimators = 150\n",
    "max_depth = 11\n",
    "learning_rate = 0.0125\n",
    "colsample_bytree = 0.5\n",
    "\n",
    "XGBM = XGBM_model(X_train,y_train,learning_rate,n_estimators,max_depth,subsample,colsample_bytree)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
    "# score,XGBM = XGBM_training(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of XGB Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Créer des séquences pour LSTM\n",
    "def create_sequences(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps)])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 60\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, time_steps)\n",
    "input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "199/199 [==============================] - 194s 949ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 2/3\n",
      "199/199 [==============================] - 165s 829ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 3/3\n",
      "199/199 [==============================] - 151s 757ms/step - loss: 0.0071 - val_loss: 0.0068\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(units=50, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "model = build_lstm_model(input_shape)\n",
    "# Entraîner le modèle\n",
    "history = model.fit(X_train_seq, y_train_seq, epochs=3, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Sauvegarder le modèle entraîné\n",
    "model.save('lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 4s 148ms/step\n",
      "Métriques pour la période de prédiction : {'MAE': 16.93707538119008}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Préparer les données de test\n",
    "data_test = df_final.loc[predict_start_date:predict_end_date]\n",
    "X_test = data_test[features]\n",
    "y_test = data_test['ROI-DA']\n",
    "\n",
    "# Normaliser les données de test\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Créer des séquences pour LSTM sur les données de test\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, time_steps)\n",
    "\n",
    "# Faire des prédictions\n",
    "y_pred_scaled = model.predict(X_test_seq)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Évaluation des prédictions\n",
    "y_test_actual = y_test.values[time_steps:]  # Ajuster les données réelles pour correspondre aux séquences\n",
    "metrics = {'MAE': mean_absolute_error(y_test_actual, y_pred)}\n",
    "print(\"Métriques pour la période de prédiction :\", metrics)\n",
    "\n",
    "# Exporter les résultats en format CSV\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual ROI-DA': y_test_actual.flatten(),\n",
    "    'Predicted ROI-DA': y_pred.flatten()\n",
    "})\n",
    "\n",
    "# now = datetime.now()\n",
    "# timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "# filename = f'results/results_lstm_{timestamp}.csv'\n",
    "\n",
    "# os.makedirs('results', exist_ok=True)\n",
    "# results_df.to_csv(filename, index=False)\n",
    "\n",
    "# print(f\"Résultats exportés dans le fichier : {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 60, 18)]     0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 60, 18)      2718        ['input_3[0][0]',                \n",
      " eadAttention)                                                    'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 60, 18)       0           ['multi_head_attention_4[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 60, 18)      36          ['dropout_14[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 60, 32)       608         ['layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 60, 32)      4748        ['dense_10[0][0]',               \n",
      " eadAttention)                                                    'dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 60, 32)       0           ['multi_head_attention_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 60, 32)      64          ['dropout_15[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 60, 32)       1056        ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 60, 1)        33          ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,263\n",
      "Trainable params: 9,263\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 4s 29ms/step - loss: 0.0300 - val_loss: 0.0067\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0113 - val_loss: 0.0070\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0101 - val_loss: 0.0070\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0095 - val_loss: 0.0085\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0087 - val_loss: 0.0092\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0082 - val_loss: 0.0136\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0084 - val_loss: 0.0125\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0077 - val_loss: 0.0198\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0078 - val_loss: 0.0143\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0076 - val_loss: 0.0189\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0084 - val_loss: 0.0137\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0078 - val_loss: 0.0231\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0085 - val_loss: 0.0167\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0078 - val_loss: 0.0204\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0072 - val_loss: 0.0159\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0072 - val_loss: 0.0207\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0072 - val_loss: 0.0153\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0070 - val_loss: 0.0198\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0071 - val_loss: 0.0129\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0068 - val_loss: 0.0229\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0070 - val_loss: 0.0148\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0071 - val_loss: 0.0273\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0067 - val_loss: 0.0240\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0068 - val_loss: 0.0221\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0066 - val_loss: 0.0332\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0065 - val_loss: 0.0299\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0065 - val_loss: 0.0253\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0067 - val_loss: 0.0332\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0067 - val_loss: 0.0260\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0066 - val_loss: 0.0252\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0065 - val_loss: 0.0443\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0070 - val_loss: 0.0312\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0064 - val_loss: 0.0319\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0069 - val_loss: 0.0209\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0068 - val_loss: 0.0215\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0062 - val_loss: 0.0181\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0067 - val_loss: 0.0261\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0064 - val_loss: 0.0241\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0065 - val_loss: 0.0192\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0063 - val_loss: 0.0140\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0060 - val_loss: 0.0186\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0066 - val_loss: 0.0093\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0061 - val_loss: 0.0154\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0064 - val_loss: 0.0100\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0060 - val_loss: 0.0130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2471f00f280>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Fonction pour construire le modèle Transformer\n",
    "def build_transformer_model(input_shape, num_heads=2, dff=32, num_layers=2):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    x = inputs\n",
    "    for _ in range(num_layers):\n",
    "        x = MultiHeadAttention(num_heads=num_heads, key_dim=input_shape[-1])(x, x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = Dense(dff, activation='relu')(x)\n",
    "    \n",
    "    # Output\n",
    "    outputs = Dense(1)(x)  # Output une seule valeur (ROI-DA prédit)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Exemple d'utilisation pour construire le modèle\n",
    "input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])\n",
    "transformer_model = build_transformer_model(input_shape)\n",
    "transformer_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Afficher la structure du modèle\n",
    "transformer_model.summary()\n",
    "\n",
    "transformer_model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 4s 29ms/step - loss: 0.0200 - val_loss: 0.0076\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0087 - val_loss: 0.0114\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.0086 - val_loss: 0.0158\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0082 - val_loss: 0.0169\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0081 - val_loss: 0.0214\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0083 - val_loss: 0.0153\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0078 - val_loss: 0.0276\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0077 - val_loss: 0.0273\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0078 - val_loss: 0.0250\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0077 - val_loss: 0.0208\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0074 - val_loss: 0.0328\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0078 - val_loss: 0.0140\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0073 - val_loss: 0.0206\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0071 - val_loss: 0.0327\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0072 - val_loss: 0.0130\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0073 - val_loss: 0.0196\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0067 - val_loss: 0.0220\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.0070 - val_loss: 0.0091\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0072 - val_loss: 0.0192\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0067 - val_loss: 0.0228\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0066 - val_loss: 0.0138\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0066 - val_loss: 0.0177\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0067 - val_loss: 0.0199\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0066 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0066 - val_loss: 0.0131\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0066 - val_loss: 0.0159\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.0065 - val_loss: 0.0133\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0068 - val_loss: 0.0134\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0064 - val_loss: 0.0116\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0064 - val_loss: 0.0097\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0064 - val_loss: 0.0119\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0062 - val_loss: 0.0109\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.0065 - val_loss: 0.0090\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0064 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0062 - val_loss: 0.0115\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0060 - val_loss: 0.0102\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.0061 - val_loss: 0.0121\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0063 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.0067 - val_loss: 0.0098\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.0059 - val_loss: 0.0095\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.0060 - val_loss: 0.0104\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.0061 - val_loss: 0.0098\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0058 - val_loss: 0.0097\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0062 - val_loss: 0.0073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2472fee2da0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour construire le modèle Transformer\n",
    "def build_transformer_model(input_shape, num_heads=2, dff=32, num_layers=2):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    x = inputs\n",
    "    for _ in range(num_layers):\n",
    "        attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=input_shape[-1])(x, x)\n",
    "        attn_output = Dense(input_shape[-1])(attn_output)  # Projection to match input dimension\n",
    "        x = LayerNormalization(epsilon=1e-6)(x + attn_output)  # Add & Norm\n",
    "        ffn_output = Dense(dff, activation='relu')(x)  # Feed-forward network\n",
    "        ffn_output = Dense(input_shape[-1])(ffn_output)  # Projection to match input dimension\n",
    "        x = LayerNormalization(epsilon=1e-6)(x + ffn_output)  # Add & Norm\n",
    "\n",
    "    # Output\n",
    "    outputs = Dense(1)(x)  # Output une seule valeur (ROI-DA prédit)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Fonction pour créer des séquences pour LSTM/Transformer\n",
    "def create_sequences(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps)])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 48, 18)]     0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 48, 18)      2718        ['input_8[0][0]',                \n",
      " HeadAttention)                                                   'input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 48, 18)       342         ['multi_head_attention_11[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 48, 18)      0           ['input_8[0][0]',                \n",
      " mbda)                                                            'dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 48, 18)      36          ['tf.__operators__.add_6[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 48, 32)       608         ['layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 48, 18)       594         ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 48, 18)      0           ['layer_normalization_14[0][0]', \n",
      " mbda)                                                            'dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 48, 18)      36          ['tf.__operators__.add_7[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (Multi  (None, 48, 18)      2718        ['layer_normalization_15[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 48, 18)       342         ['multi_head_attention_12[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 48, 18)      0           ['layer_normalization_15[0][0]', \n",
      " mbda)                                                            'dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 48, 18)      36          ['tf.__operators__.add_8[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 48, 32)       608         ['layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 48, 18)       594         ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  (None, 48, 18)      0           ['layer_normalization_16[0][0]', \n",
      " mbda)                                                            'dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 48, 18)      36          ['tf.__operators__.add_9[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 48, 1)        19          ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,687\n",
      "Trainable params: 8,687\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/3\n",
      "100/100 [==============================] - 6s 43ms/step - loss: 0.0370 - val_loss: 0.0304\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.0095 - val_loss: 0.0175\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0091 - val_loss: 0.0140\n",
      "21/21 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[161], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Évaluation des prédictions\u001b[39;00m\n\u001b[0;32m     42\u001b[0m y_pred_scaled \u001b[38;5;241m=\u001b[39m transformer_model\u001b[38;5;241m.\u001b[39mpredict(X_test_seq)\n\u001b[1;32m---> 43\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mscaler_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Ajuster y_test pour correspondre à y_test_seq\u001b[39;00m\n\u001b[0;32m     46\u001b[0m y_test_seq_actual \u001b[38;5;241m=\u001b[39m y_test_scaled[time_steps:]\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\summer2023\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:537\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Undo the scaling of X according to feature_range.\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;124;03m    Transformed data.\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    535\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 537\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    539\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n\u001b[0;32m    542\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\summer2023\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m     )\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    921\u001b[0m     _assert_all_finite(\n\u001b[0;32m    922\u001b[0m         array,\n\u001b[0;32m    923\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    924\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    925\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    926\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Préparer les données de test\n",
    "data_test = df_final.loc[predict_start_date:predict_end_date]\n",
    "X_test = data_test[features]\n",
    "y_test = data_test['ROI-DA']\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "time_steps = 48\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, time_steps)\n",
    "\n",
    "# Préparer les données de test\n",
    "data_test = df_final.loc[predict_start_date:predict_end_date]\n",
    "X_test = data_test[features]\n",
    "y_test = data_test['ROI-DA']\n",
    "\n",
    "# Normaliser les données de test\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Créer des séquences pour le test\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, time_steps)\n",
    "\n",
    "# Construction et entraînement du modèle Transformer\n",
    "input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])\n",
    "transformer_model = build_transformer_model(input_shape)\n",
    "transformer_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "transformer_model.summary()\n",
    "transformer_model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    epochs=3,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Évaluation des prédictions\n",
    "y_pred_scaled = transformer_model.predict(X_test_seq)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Ajuster y_test pour correspondre à y_test_seq\n",
    "y_test_seq_actual = y_test_scaled[time_steps:]\n",
    "\n",
    "# Inverser la transformation pour y_test_seq_actual\n",
    "y_test_seq_actual = scaler_y.inverse_transform(y_test_seq_actual)\n",
    "\n",
    "# Évaluation des prédictions (par exemple, calculer le Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_test_seq_actual, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Affichage des prédictions et des vraies valeurs (facultatif)\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_seq_actual, label='True ROI-DA', marker='.')\n",
    "plt.plot(y_pred, label='Predicted ROI-DA', marker='.')\n",
    "plt.title('True vs Predicted ROI-DA')\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('ROI-DA')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métriques pour la période de prédiction : {'MAE': np.float64(8.457132932643809)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_start_date = pd.to_datetime(predict_start_date)\n",
    "predict_end_date = pd.to_datetime(predict_end_date)\n",
    "data_test = df_final.loc[predict_start_date:predict_end_date]\n",
    "X_test = data_test[features]\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = XGBM.predict(X_test)\n",
    "\n",
    "y_true = data_test['ROI-DA']\n",
    "metrics = eval_metrics(y_true, y_pred)\n",
    "print(\"Métriques pour la période de prédiction :\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Feature        Score        p-Value\n",
      "2   ROI-DA_lag_48h  2326.000460   0.000000e+00\n",
      "5   ROI-DA_lag_49h  1748.572402   0.000000e+00\n",
      "8   ROI-DA_lag_50h   948.543423  6.401506e-197\n",
      "15            hour   893.632993  3.224883e-186\n",
      "1      Gas_lag_48h   463.534010  5.469151e-100\n",
      "4      Gas_lag_49h   463.311213  6.077771e-100\n",
      "7      Gas_lag_50h   462.972184  7.136376e-100\n",
      "10     Gas_lag_51h   462.256921   1.001397e-99\n",
      "13     Gas_lag_52h   461.311220   1.567313e-99\n",
      "11  ROI-DA_lag_51h   428.331642   9.861167e-93\n",
      "0      Oil_lag_48h   339.213665   3.210587e-74\n",
      "3      Oil_lag_49h   338.644120   4.222528e-74\n",
      "6      Oil_lag_50h   337.771573   6.425096e-74\n",
      "9      Oil_lag_51h   336.734115   1.058448e-73\n",
      "12     Oil_lag_52h   335.603186   1.823999e-73\n",
      "17     day_of_year   215.146720   4.355626e-48\n",
      "14  ROI-DA_lag_52h   157.204057   1.000974e-35\n",
      "16     day_of_week   126.194107   4.602436e-29\n"
     ]
    }
   ],
   "source": [
    "feature_scores = selector.scores_\n",
    "feature_pvalues = selector.pvalues_\n",
    "\n",
    "# Créer un DataFrame pour afficher les résultats\n",
    "feature_names = X_train.columns\n",
    "scores_df = pd.DataFrame({'Feature': feature_names, 'Score': feature_scores, 'p-Value': feature_pvalues})\n",
    "\n",
    "# Trier le DataFrame par score décroissant\n",
    "scores_df = scores_df.sort_values(by='Score', ascending=False)\n",
    "print(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MAE\n",
      "0  8.457133\n",
      "Résultats exportés dans le fichier : results/results_20240704_110948.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Ajouter les métriques au dataframe\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "print(metrics_df)\n",
    "\n",
    "# Générer le nom de fichier avec la date et l'heure actuelles\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f'results/results_{timestamp}.csv'\n",
    "\n",
    "# Créer le répertoire 'results' s'il n'existe pas\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "# Exporter les scores, les p-values et les métriques MAE dans un fichier CSV\n",
    "full_results_df = pd.concat([scores_df, metrics_df], axis=1)\n",
    "# full_results_df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Résultats exportés dans le fichier : {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m prediction_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(index\u001b[38;5;241m=\u001b[39mdata_test\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m----> 2\u001b[0m prediction_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROI-DA réel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43my_true\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      3\u001b[0m prediction_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROI-DA prédit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_pred\n\u001b[0;32m      4\u001b[0m prediction_results\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020 04 01\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020 04 28\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "prediction_results = pd.DataFrame(index=data_test.index)\n",
    "prediction_results['ROI-DA réel'] = y_true.values\n",
    "prediction_results['ROI-DA prédit'] = y_pred\n",
    "prediction_results.loc['2020 04 01':'2020 04 28'].plot()\n",
    "plt.legend()\n",
    "plt.ylabel('euro(€)')\n",
    "plt.xlabel('days')\n",
    "plt.title('ROI-DA prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my_true\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[11:09:49] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:508: Check failed: this->labels.Size() % this->num_row_ == 0 (48 vs. 0) : Incorrect size for labels.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[139], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m y_train \u001b[38;5;241m=\u001b[39m data_train\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m48\u001b[39m:][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROI-DA\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Les 48 dernières valeurs de ROI-DA pour prédire les deux prochains jours \u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Conversion en DMatrix pour XGBoost\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Définir les paramètres du modèle\u001b[39;00m\n\u001b[0;32m     50\u001b[0m num_round \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\sklearn.py:1081\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[0;32m   1080\u001b[0m     evals_result: TrainingCallback\u001b[38;5;241m.\u001b[39mEvalsLog \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1081\u001b[0m     train_dmatrix, evals \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\sklearn.py:596\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[0;32m    577\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m    578\u001b[0m     X: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    592\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    593\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m    594\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;124;03m    way.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 596\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\sklearn.py:1003\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_method) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1003\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m QuantileDMatrix(\n\u001b[0;32m   1004\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, ref\u001b[38;5;241m=\u001b[39mref, nthread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, max_bin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bin\n\u001b[0;32m   1005\u001b[0m         )\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:1573\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1554\u001b[0m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1555\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m         )\n\u001b[0;32m   1567\u001b[0m     ):\n\u001b[0;32m   1568\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf data iterator is used as input, data like label should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1570\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified as batch argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1571\u001b[0m         )\n\u001b[1;32m-> 1573\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1586\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1587\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:1632\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[1;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[0;32m   1620\u001b[0m config \u001b[38;5;241m=\u001b[39m make_jcargs(\n\u001b[0;32m   1621\u001b[0m     nthread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnthread, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing, max_bin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bin\n\u001b[0;32m   1622\u001b[0m )\n\u001b[0;32m   1623\u001b[0m ret \u001b[38;5;241m=\u001b[39m _LIB\u001b[38;5;241m.\u001b[39mXGQuantileDMatrixCreateFromCallback(\n\u001b[0;32m   1624\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1625\u001b[0m     it\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1630\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mbyref(handle),\n\u001b[0;32m   1631\u001b[0m )\n\u001b[1;32m-> 1632\u001b[0m \u001b[43mit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[0;32m   1634\u001b[0m _check_call(ret)\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:569\u001b[0m, in \u001b[0;36mDataIter.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    567\u001b[0m exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:550\u001b[0m, in \u001b[0;36mDataIter._handle_exception\u001b[1;34m(self, fn, dft_ret)\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dft_ret\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;66;03m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;66;03m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;66;03m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[0;32m    555\u001b[0m     tb \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:637\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temporary_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_exception(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\data.py:1416\u001b[0m, in \u001b[0;36mSingleBatchInternalIter.next\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mit \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1416\u001b[0m input_data(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:626\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.input_data\u001b[1;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temporary_data \u001b[38;5;241m=\u001b[39m (new, cat_codes, feature_names, feature_types)\n\u001b[0;32m    625\u001b[0m dispatch_proxy_set_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy, new, cat_codes)\n\u001b[1;32m--> 626\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mset_info(\n\u001b[0;32m    627\u001b[0m     feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[0;32m    628\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    630\u001b[0m )\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_ref \u001b[38;5;241m=\u001b[39m ref\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:954\u001b[0m, in \u001b[0;36mDMatrix.set_info\u001b[1;34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch_meta_backend\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_weight(weight)\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:1092\u001b[0m, in \u001b[0;36mDMatrix.set_label\u001b[1;34m(self, label)\u001b[0m\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set label of dmatrix\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m \n\u001b[0;32m   1085\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;124;03m    The label information to be set into DMatrix\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch_meta_backend\n\u001b[1;32m-> 1092\u001b[0m \u001b[43mdispatch_meta_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\data.py:1362\u001b[0m, in \u001b[0;36mdispatch_meta_backend\u001b[1;34m(matrix, data, name, dtype)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_series(data):\n\u001b[1;32m-> 1362\u001b[0m     \u001b[43m_meta_from_pandas_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_dlpack(data):\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\data.py:679\u001b[0m, in \u001b[0;36m_meta_from_pandas_series\u001b[1;34m(data, name, dtype, handle)\u001b[0m\n\u001b[0;32m    677\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_dense()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 679\u001b[0m \u001b[43m_meta_from_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\data.py:1295\u001b[0m, in \u001b[0;36m_meta_from_numpy\u001b[1;34m(data, field, dtype, handle)\u001b[0m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMasked array is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1294\u001b[0m interface_str \u001b[38;5;241m=\u001b[39m _array_interface(data)\n\u001b[1;32m-> 1295\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGDMatrixSetInfoFromInterface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:284\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [11:09:49] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:508: Check failed: this->labels.Size() % this->num_row_ == 0 (48 vs. 0) : Incorrect size for labels."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "start_date = '2019-06-01'\n",
    "end_date = '2020-04-07'\n",
    "predict_start_date = '2020-04-08'\n",
    "predict_end_date = '2020-04-14'  # Prédiction pour la semaine suivante\n",
    "number_days = 7\n",
    "results = []\n",
    "\n",
    "# Initialiser les dates\n",
    "current_date = pd.to_datetime(start_date) + pd.Timedelta(days=number_days)\n",
    "end_date = pd.to_datetime(end_date)\n",
    "predict_start_date = pd.to_datetime(predict_start_date)\n",
    "predict_end_date = pd.to_datetime(predict_end_date)\n",
    "# Fonction d'évaluation des métriques\n",
    "def eval_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return {'MAE': mae}\n",
    "\n",
    "params = {\n",
    "    'objective': 'reg:squarederror', \n",
    "    'max_depth': 6,                   \n",
    "    'eta': 0.05,                       \n",
    "    'eval_metric': 'rmse',             \n",
    "    'subsample': 0.8,                 \n",
    "    'colsample_bytree': 0.8,           \n",
    "    'gamma': 0                         \n",
    "}\n",
    "model = xgb.XGBRegressor(**params)\n",
    "\n",
    "\n",
    "# Filtrer les données pour l'entraînement sur 10 mois\n",
    "train_start_date = pd.to_datetime(start_date)\n",
    "train_end_date = end_date - pd.Timedelta(days=number_days)\n",
    "data_train = df_final.loc[train_start_date:train_end_date]\n",
    "\n",
    "# # Calcul des moyennes horaires sur les 7 jours précédents pour ROI-DA\n",
    "# hourly_mean = data_train['ROI-DA'].groupby(data_train.index.hour).mean()\n",
    "# df_final['7_day_hourly_mean'] = df_final.index.map(hourly_mean)\n",
    "\n",
    "# Préparer les données pour l'entraînement\n",
    "X_train = data_train.iloc[:-48][['Oil', 'Gas','ROI-DA']]\n",
    "y_train = data_train.iloc[-48:]['ROI-DA']  # Les 48 dernières valeurs de ROI-DA pour prédire les deux prochains jours \n",
    "\n",
    "# Conversion en DMatrix pour XGBoost\n",
    "model.fit(X_train, y_train)\n",
    "# Définir les paramètres du modèle\n",
    "num_round = 1000\n",
    "# bst = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# Préparer les données de test pour la semaine suivante à partir du 8 avril 2020\n",
    "data_test = df_final.loc[predict_start_date:predict_end_date]\n",
    "X_test = data_test.iloc[:-48][['Oil', 'Gas', 'ROI-DA']]\n",
    "\n",
    "# Conversion en DMatrix pour XGBoost\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# # Faire des prédictions\n",
    "# y_pred = bst.predict(dtest)\n",
    "\n",
    "# Évaluation des prédictions (optionnel, pour vérification)\n",
    "y_true = data_test.iloc[-48:]['ROI-DA']\n",
    "metrics = eval_metrics(y_true, y_pred)\n",
    "print(\"Metrics for prediction period:\", metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[11:29:43] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:508: Check failed: this->labels.Size() % this->num_row_ == 0 (346824 vs. 0) : Incorrect size for labels.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[210], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m y_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(y_train)\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# Convertir en un tableau NumPy\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Conversion en DMatrix pour XGBoost\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Définir les paramètres du modèle\u001b[39;00m\n\u001b[0;32m     37\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Pour un problème de régression\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m6\u001b[39m,                    \u001b[38;5;66;03m# Profondeur des arbres plus grande\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m                         \u001b[38;5;66;03m# Pas de réduction minimale de la perte\u001b[39;00m\n\u001b[0;32m     45\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:890\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n\u001b[1;32m--> 890\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names \u001b[38;5;241m=\u001b[39m feature_names\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:954\u001b[0m, in \u001b[0;36mDMatrix.set_info\u001b[1;34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch_meta_backend\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_weight(weight)\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:1092\u001b[0m, in \u001b[0;36mDMatrix.set_label\u001b[1;34m(self, label)\u001b[0m\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set label of dmatrix\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m \n\u001b[0;32m   1085\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;124;03m    The label information to be set into DMatrix\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch_meta_backend\n\u001b[1;32m-> 1092\u001b[0m \u001b[43mdispatch_meta_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\data.py:1354\u001b[0m, in \u001b[0;36mdispatch_meta_backend\u001b[1;34m(matrix, data, name, dtype)\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_np_array_like(data):\n\u001b[1;32m-> 1354\u001b[0m     \u001b[43m_meta_from_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_arrow(data):\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\data.py:1295\u001b[0m, in \u001b[0;36m_meta_from_numpy\u001b[1;34m(data, field, dtype, handle)\u001b[0m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMasked array is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1294\u001b[0m interface_str \u001b[38;5;241m=\u001b[39m _array_interface(data)\n\u001b[1;32m-> 1295\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGDMatrixSetInfoFromInterface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\xgboost\\core.py:284\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [11:29:43] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:508: Check failed: this->labels.Size() % this->num_row_ == 0 (346824 vs. 0) : Incorrect size for labels."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "# Charger et préparer les données\n",
    "# Exemple de chargement de données fictives\n",
    "\n",
    "\n",
    "# Définir les dates\n",
    "start_date = '2019-06-01'\n",
    "end_date = '2020-04-07'\n",
    "number_days = 7\n",
    "\n",
    "# Filtrer les données pour l'entraînement sur 10 mois\n",
    "train_start_date = pd.to_datetime(start_date)\n",
    "train_end_date = pd.to_datetime(end_date) - pd.Timedelta(days=number_days)\n",
    "data_train = df_final.loc[train_start_date:train_end_date]\n",
    "\n",
    "# Préparer les données pour l'entraînement\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Création des échantillons d'entraînement et des cibles de prédiction\n",
    "for i in range(len(data_train) - 48):\n",
    "    X_window = data_train[['Oil', 'Gas', 'ROI-DA']].iloc[i:i+48]  # Caractéristiques sur les 48 dernières heures\n",
    "    y_window = data_train['ROI-DA'].iloc[i+48:i+96]              # ROI-DA pour les 48 prochaines heures\n",
    "    X_train.append(X_window)\n",
    "    y_train.append(y_window)\n",
    "\n",
    "# Concaténer les listes en DataFrame\n",
    "X_train = pd.concat(X_train)\n",
    "y_train = pd.concat(y_train).values  # Convertir en un tableau NumPy\n",
    "\n",
    "# Conversion en DMatrix pour XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# Définir les paramètres du modèle\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',  # Pour un problème de régression\n",
    "    'max_depth': 6,                    # Profondeur des arbres plus grande\n",
    "    'eta': 0.05,                       # Taux d'apprentissage plus faible\n",
    "    'eval_metric': 'rmse',             # Erreur quadratique moyenne racine\n",
    "    'subsample': 0.8,                  # Sous-échantillonnage des échantillons\n",
    "    'colsample_bytree': 0.8,           # Sous-échantillonnage des features\n",
    "    'gamma': 0                         # Pas de réduction minimale de la perte\n",
    "}\n",
    "num_round = 1000\n",
    "bst = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# Prédiction des prochaines 48 heures\n",
    "# Utilisation des données les plus récentes disponibles pour faire la prédiction\n",
    "X_recent = data_train[['Oil', 'Gas', 'ROI-DA']].tail(48)  # Sélectionner les 48 dernières lignes de X_train\n",
    "\n",
    "# Conversion en DMatrix pour XGBoost\n",
    "drecent = xgb.DMatrix(X_recent)\n",
    "\n",
    "# Faire des prédictions pour les 48 prochaines heures\n",
    "y_pred = bst.predict(drecent)\n",
    "\n",
    "# Afficher les prédictions\n",
    "print(\"Predicted ROI-DA for the next 48 hours:\")\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>{'MAE': 0.12910339565934797}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>{'MAE': 0.12649279574690175}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>{'MAE': 0.14494916139800004}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>{'MAE': 0.11951590676143278}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-06</td>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>{'MAE': 0.13356749225484943}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-07-13</td>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>{'MAE': 0.16253624435951003}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>{'MAE': 0.14154209429642214}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>{'MAE': 0.15638298718682644}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-08-03</td>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>{'MAE': 0.12607029197955935}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>{'MAE': 0.16883613218110194}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>{'MAE': 0.14734087003510563}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-08-24</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>{'MAE': 0.18313450464709094}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>{'MAE': 0.11453018162168341}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-09-07</td>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>{'MAE': 0.1069693585159899}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>{'MAE': 0.3419474671462488}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>2019-09-27</td>\n",
       "      <td>{'MAE': 0.11363262212019569}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-09-28</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>{'MAE': 0.13928250328425715}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-10-05</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>{'MAE': 0.18131700756632055}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-10-12</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>{'MAE': 0.1368404028004613}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-10-19</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>{'MAE': 0.18107149900239106}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-10-26</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>{'MAE': 0.1104274918077321}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>2019-11-08</td>\n",
       "      <td>{'MAE': 0.10080825568889754}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-11-09</td>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>{'MAE': 0.13432583820839125}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-11-16</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>{'MAE': 0.19213111193426702}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-11-23</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>{'MAE': 0.16184976490941566}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>{'MAE': 0.3754386141020677}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-12-07</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>{'MAE': 0.35585894034587134}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>{'MAE': 0.19060836733004152}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-12-21</td>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>{'MAE': 0.6023669060530334}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>{'MAE': 0.14473948026443337}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>{'MAE': 0.13815104955763657}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>{'MAE': 0.18026915642865748}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>{'MAE': 0.39142598182415117}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>{'MAE': 0.12329793075035364}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>{'MAE': 0.15001503839410557}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2020-02-08</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>{'MAE': 0.21445724694811044}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>{'MAE': 0.1907776531367209}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>{'MAE': 0.17749304939302896}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>{'MAE': 0.143133287243391}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>{'MAE': 0.18854129271918327}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>{'MAE': 0.1352986691442031}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>{'MAE': 0.1061596324131406}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>{'MAE': 0.1651535975226042}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date   end_date                       metrics\n",
       "0  2019-06-08 2019-06-14  {'MAE': 0.12910339565934797}\n",
       "1  2019-06-15 2019-06-21  {'MAE': 0.12649279574690175}\n",
       "2  2019-06-22 2019-06-28  {'MAE': 0.14494916139800004}\n",
       "3  2019-06-29 2019-07-05  {'MAE': 0.11951590676143278}\n",
       "4  2019-07-06 2019-07-12  {'MAE': 0.13356749225484943}\n",
       "5  2019-07-13 2019-07-19  {'MAE': 0.16253624435951003}\n",
       "6  2019-07-20 2019-07-26  {'MAE': 0.14154209429642214}\n",
       "7  2019-07-27 2019-08-02  {'MAE': 0.15638298718682644}\n",
       "8  2019-08-03 2019-08-09  {'MAE': 0.12607029197955935}\n",
       "9  2019-08-10 2019-08-16  {'MAE': 0.16883613218110194}\n",
       "10 2019-08-17 2019-08-23  {'MAE': 0.14734087003510563}\n",
       "11 2019-08-24 2019-08-30  {'MAE': 0.18313450464709094}\n",
       "12 2019-08-31 2019-09-06  {'MAE': 0.11453018162168341}\n",
       "13 2019-09-07 2019-09-13   {'MAE': 0.1069693585159899}\n",
       "14 2019-09-14 2019-09-20   {'MAE': 0.3419474671462488}\n",
       "15 2019-09-21 2019-09-27  {'MAE': 0.11363262212019569}\n",
       "16 2019-09-28 2019-10-04  {'MAE': 0.13928250328425715}\n",
       "17 2019-10-05 2019-10-11  {'MAE': 0.18131700756632055}\n",
       "18 2019-10-12 2019-10-18   {'MAE': 0.1368404028004613}\n",
       "19 2019-10-19 2019-10-25  {'MAE': 0.18107149900239106}\n",
       "20 2019-10-26 2019-11-01   {'MAE': 0.1104274918077321}\n",
       "21 2019-11-02 2019-11-08  {'MAE': 0.10080825568889754}\n",
       "22 2019-11-09 2019-11-15  {'MAE': 0.13432583820839125}\n",
       "23 2019-11-16 2019-11-22  {'MAE': 0.19213111193426702}\n",
       "24 2019-11-23 2019-11-29  {'MAE': 0.16184976490941566}\n",
       "25 2019-11-30 2019-12-06   {'MAE': 0.3754386141020677}\n",
       "26 2019-12-07 2019-12-13  {'MAE': 0.35585894034587134}\n",
       "27 2019-12-14 2019-12-20  {'MAE': 0.19060836733004152}\n",
       "28 2019-12-21 2019-12-27   {'MAE': 0.6023669060530334}\n",
       "29 2019-12-28 2020-01-03  {'MAE': 0.14473948026443337}\n",
       "30 2020-01-04 2020-01-10  {'MAE': 0.13815104955763657}\n",
       "31 2020-01-11 2020-01-17  {'MAE': 0.18026915642865748}\n",
       "32 2020-01-18 2020-01-24  {'MAE': 0.39142598182415117}\n",
       "33 2020-01-25 2020-01-31  {'MAE': 0.12329793075035364}\n",
       "34 2020-02-01 2020-02-07  {'MAE': 0.15001503839410557}\n",
       "35 2020-02-08 2020-02-14  {'MAE': 0.21445724694811044}\n",
       "36 2020-02-15 2020-02-21   {'MAE': 0.1907776531367209}\n",
       "37 2020-02-22 2020-02-28  {'MAE': 0.17749304939302896}\n",
       "38 2020-02-29 2020-03-06    {'MAE': 0.143133287243391}\n",
       "39 2020-03-07 2020-03-13  {'MAE': 0.18854129271918327}\n",
       "40 2020-03-14 2020-03-20   {'MAE': 0.1352986691442031}\n",
       "41 2020-03-21 2020-03-27   {'MAE': 0.1061596324131406}\n",
       "42 2020-03-28 2020-04-03   {'MAE': 0.1651535975226042}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'dict' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculer la moyenne des MAE\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m mean_mae \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetrics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean MAE over the year: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_mae\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Afficher les résultats dans un plot\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\pandas\\core\\series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6548\u001b[0m ):\n\u001b[1;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\pandas\\core\\generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  12422\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  12379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\pandas\\core\\series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6452\u001b[0m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[0;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6456\u001b[0m     )\n\u001b[1;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\pandas\\core\\nanops.py:719\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    716\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\nimbus\\anaconda3\\envs\\Optim\\lib\\site-packages\\numpy\\_core\\_methods.py:52\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     51\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict' and 'dict'"
     ]
    }
   ],
   "source": [
    "# Calculer la moyenne des MAE\n",
    "mean_mae = results_df['metrics'].mean()\n",
    "print(f\"Mean MAE over the year: {mean_mae}\")\n",
    "\n",
    "# Afficher les résultats dans un plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(results_df['date'], results_df['metrics'], label='Daily MAE')\n",
    "plt.axhline(y=mean_mae, color='r', linestyle='--', label=f'Mean MAE: {mean_mae:.2f}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean Absolute Error (MAE)')\n",
    "plt.title('Daily MAE Over One Year')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7027, 1)\n",
      "(1757, 1)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split_tbs(final_data):\n",
    "    train,test = final_data.iloc[:int(0.8*final_data.shape[0]), :] , final_data.iloc[int(0.8*final_data.shape[0]):, :]\n",
    "    print(train.shape)\n",
    "    print(test.shape)\n",
    "    \n",
    "    return train,test\n",
    "\n",
    "datatrain,datatest = train_test_split_tbs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tableau de corrélation avec la colonne ROI-DA :\n",
      "ROI-DA    1.0\n",
      "Name: ROI-DA, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = data.corr()\n",
    "\n",
    "# Afficher le tableau de corrélation avec la colonne ROI-DA\n",
    "correlation_with_ROI_DA = correlation_matrix['ROI-DA']\n",
    "\n",
    "print(\"Tableau de corrélation avec la colonne ROI-DA :\")\n",
    "print(correlation_with_ROI_DA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize(x_train,x_test):\n",
    "#     from sklearn.preprocessing import MinMaxScaler\n",
    "#     scaler = MinMaxScaler().fit(x_train)\n",
    "#     x_train_norm = scaler.transform(x_train)\n",
    "#     x_test_norm = scaler.transform(x_test)\n",
    "#     return x_train_norm,x_test_norm\n",
    "\n",
    "# datatrain,datatest = normalize(datatrain,datatest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatrain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Optim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
